{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina uma variável global para armazenar o modelo treinado\n",
    "global model\n",
    "model = None\n",
    "\n",
    "# Obtenha o diretório atual de trabalho\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "# Define o diretório onde suas imagens estão localizadas\n",
    "data_dir = os.path.join(script_dir, 'Base_de_Dados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    # Carregue a imagem original\n",
    "    imagem = cv2.imread(img_path)\n",
    "\n",
    "    # Verifique se a imagem foi carregada com sucesso\n",
    "    if imagem is None:\n",
    "        print(f\"Erro ao carregar a imagem: {img_path}\")\n",
    "        return None  # Retorne None para indicar que o processamento falhou\n",
    "\n",
    "    # Redimensionando a imagem\n",
    "    imagem_redimensionada = cv2.resize(imagem, (224, 224))\n",
    "\n",
    "    # Aumento de contraste\n",
    "    imagem_em_escala_de_cinza = cv2.cvtColor(imagem_redimensionada, cv2.COLOR_BGR2GRAY)\n",
    "    #imagem_em_escala_de_cinza = cv2.equalizeHist(imagem_em_escala_de_cinza)\n",
    "\n",
    "    # Retorne a imagem processada\n",
    "    return imagem_em_escala_de_cinza  # Mantenha a matriz 2D em escala de cinza com aumento de contraste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ImageDataGenerator para carregar os dados\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)  # Normalização\n",
    "\n",
    "# Carregue os dados em um array numpy\n",
    "image_data = []\n",
    "image_labels = []\n",
    "\n",
    "for subdir in os.listdir(data_dir):\n",
    "    sub_dir_path = os.path.join(data_dir, subdir)\n",
    "    if os.path.isdir(sub_dir_path):\n",
    "        for img_file in os.listdir(sub_dir_path):\n",
    "            img_path = os.path.join(sub_dir_path, img_file)\n",
    "            image_data.append(img_path)\n",
    "            image_labels.append(subdir)\n",
    "\n",
    "image_data = np.array(image_data)\n",
    "image_labels = np.array(image_labels)\n",
    "labels = np.unique(image_labels)\n",
    "\n",
    "# Defina o número de folds\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Variáveis para armazenar resultados\n",
    "all_train_histories = []\n",
    "all_val_histories = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Defina o valor de batch_size\n",
    "batch_size = 32  # Você pode ajustar esse valor conforme necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(nome_do_modelo):\n",
    "    global model  # Use a variável global\n",
    "\n",
    "    # Variável para armazenar informações de cada fold\n",
    "    fold_info = []\n",
    "\n",
    "    # Loop através dos folds\n",
    "    for i, (train_index, val_index) in enumerate(kf.split(image_data), 1):\n",
    "        train_data = image_data[train_index]\n",
    "        train_labels = image_labels[train_index]\n",
    "        val_data = image_data[val_index]\n",
    "        val_labels = image_labels[val_index]\n",
    "\n",
    "        # Pré-processar as imagens de treinamento e validação\n",
    "        train_data_processed = [preprocess_image(img_path) for img_path in train_data]\n",
    "        val_data_processed = [preprocess_image(img_path) for img_path in val_data]\n",
    "\n",
    "        # Remova entradas None (imagens que não puderam ser carregadas)\n",
    "        train_data_processed = [img for img in train_data_processed if img is not None]\n",
    "        val_data_processed = [img for img in val_data_processed if img is not None]\n",
    "\n",
    "        # Converter as imagens em listas de matrizes 1D\n",
    "        train_data_processed = [img.flatten() for img in train_data_processed]\n",
    "        val_data_processed = [img.flatten() for img in val_data_processed]\n",
    "\n",
    "        # Converta as listas em arrays numpy\n",
    "        train_data_processed = np.array(train_data_processed)\n",
    "        val_data_processed = np.array(val_data_processed)\n",
    "\n",
    "        train_df = pd.DataFrame({'filename': train_data, 'class': train_labels})\n",
    "        val_df = pd.DataFrame({'filename': val_data, 'class': val_labels})\n",
    "\n",
    "        train_generator = datagen.flow_from_dataframe(\n",
    "            dataframe=train_df,\n",
    "            x_col='filename',\n",
    "            y_col='class',\n",
    "            target_size=(224, 224),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        val_generator = datagen.flow_from_dataframe(\n",
    "            dataframe=val_df,\n",
    "            x_col='filename',\n",
    "            y_col='class',\n",
    "            target_size=(224, 224),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        # Crie e compile o modelo (certifique-se de usar o número correto de classes)\n",
    "        num_classes = len(np.unique(train_labels))\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "        model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "        model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "        model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))  # Use o número correto de unidades\n",
    "\n",
    "        model.compile(optimizer='rmsprop',\n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        # Treine o modelo por 5 época (ou o número de épocas desejado)\n",
    "        history = model.fit(train_generator, epochs=5, validation_data=val_generator)\n",
    "\n",
    "        # Avalie o modelo no conjunto de teste (val_generator)\n",
    "        y_true = val_generator.classes  # Rótulos reais\n",
    "        y_pred_probs = model.predict(val_generator)  # Probabilidades das previsões\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)  # Rótulos previstos\n",
    "\n",
    "        # Calcule a matriz de confusão\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        # Calcula a precisão para cada classe\n",
    "        num_classes = cm.shape[0]\n",
    "        precisao_por_classe = []\n",
    "        for classe in range(num_classes):\n",
    "            TP = cm[classe, classe]  # Verdadeiros Positivos\n",
    "            FP = np.sum(cm[:, classe]) - TP  # Falsos Positivos\n",
    "            precision = TP / (TP + FP)\n",
    "            precisao_por_classe.append(precision)\n",
    "\n",
    "        # Armazena informações do fold em fold_info\n",
    "        fold_info.append({\n",
    "            'Fold': i,\n",
    "            'Loss': history.history['loss'],\n",
    "            'Accuracy': history.history['accuracy'],\n",
    "            'Validation Loss': history.history['val_loss'],\n",
    "            'Validation Accuracy': history.history['val_accuracy'],\n",
    "            'Confusion Matrix': cm,\n",
    "            'Precision per Class': precisao_por_classe\n",
    "        })\n",
    "\n",
    "    # Salve o modelo treinado com o nome especificado\n",
    "    model.save(nome_do_modelo)\n",
    "\n",
    "    # Retorne o modelo e as informações de cada fold\n",
    "    return model, fold_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_matriz_confusao_e_precisao(model, nome_do_modelo, labels, confusion_matrices):\n",
    "    # Crie a matriz de confusão geral\n",
    "    overall_confusion_matrix = np.sum(confusion_matrices, axis=0)\n",
    "\n",
    "    # Calcula a precisão para cada classe\n",
    "    num_classes = overall_confusion_matrix.shape[0]\n",
    "    precisao_por_classe = []\n",
    "\n",
    "    for classe in range(num_classes):\n",
    "        TP = overall_confusion_matrix[classe, classe]  # Verdadeiros Positivos\n",
    "        FP = np.sum(overall_confusion_matrix[:, classe]) - TP  # Falsos Positivos\n",
    "        precision = TP / (TP + FP)\n",
    "        precisao_por_classe.append(precision)\n",
    "\n",
    "    return {\n",
    "        'Matriz de Confusão Geral': overall_confusion_matrix,\n",
    "        'Precisão por Classe': precisao_por_classe\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para exibir informações de cada fold\n",
    "def exibir_informacoes_fold(fold_info, labels):\n",
    "    all_accuracy = []\n",
    "    all_val_accuracy = []\n",
    "    all_precision = []\n",
    "    all_confusion_matrices = []\n",
    "\n",
    "    for fold_data in fold_info:\n",
    "        fold = fold_data['Fold']\n",
    "        loss = fold_data['Loss']\n",
    "        accuracy = fold_data['Accuracy']\n",
    "        val_loss = fold_data['Validation Loss']\n",
    "        val_accuracy = fold_data['Validation Accuracy']\n",
    "        confusion_matrix_fold = fold_data['Confusion Matrix']\n",
    "        precisao_por_classe_fold = fold_data['Precision per Class']\n",
    "\n",
    "        print(f'Fold {fold}:')\n",
    "        print(f'Loss: {loss}')\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "        print(f'Validation Loss: {val_loss}')\n",
    "        print(f'Validation Accuracy: {val_accuracy}')\n",
    "\n",
    "        print(\"Matriz de Confusão:\")\n",
    "        print(confusion_matrix_fold)\n",
    "\n",
    "        print(\"\\nPrecisão por Classe:\")\n",
    "        for classe, precision in enumerate(precisao_por_classe_fold):\n",
    "            classe_nome = labels[classe]\n",
    "            print(f\"Classe '{classe_nome}': Precisão = '{precision:.4f}'\")\n",
    "\n",
    "        all_accuracy.append(accuracy[-1])\n",
    "        all_val_accuracy.append(val_accuracy[-1])\n",
    "        all_precision.append(precisao_por_classe_fold)\n",
    "        all_confusion_matrices.append(confusion_matrix_fold)\n",
    "\n",
    "    num_folds = len(fold_info)\n",
    "\n",
    "    # Calcular médias\n",
    "    average_accuracy = np.mean(all_accuracy)\n",
    "    average_val_accuracy = np.mean(all_val_accuracy)\n",
    "    average_precision = np.mean(all_precision, axis=0)\n",
    "\n",
    "    print(f'\\nAcurácia Média entre os {num_folds} folds: {average_accuracy:.4f}')\n",
    "    print(f'Acurácia de Validação Média entre os {num_folds} folds: {average_val_accuracy:.4f}')\n",
    "\n",
    "    # Calcular a matriz de confusão geral (somatório das matrizes dos folds)\n",
    "    confusion_matrix_general = np.sum(all_confusion_matrices, axis=0)\n",
    "\n",
    "    print(\"\\nMatriz de Confusão Geral (Somatório das Matrizes dos Folds):\")\n",
    "    print(confusion_matrix_general)\n",
    "\n",
    "    print(\"\\nPrecisão Média por Classe:\")\n",
    "    for classe, precision in enumerate(average_precision):\n",
    "        classe_nome = labels[classe]\n",
    "        print(f\"Classe '{classe_nome}': Precisão Média = '{precision:.4f}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar o modelo treinado com um nome especificado ou treiná-lo se necessário\n",
    "def carregar_ou_treinar_modelo(nome_do_modelo):\n",
    "    global model\n",
    "    if model is None:\n",
    "        if os.path.exists(nome_do_modelo):\n",
    "            model = tf.keras.models.load_model(nome_do_modelo)\n",
    "        else:\n",
    "            model = treino(nome_do_modelo)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_for_prediction(img_path):\n",
    "    # Carregue a imagem original\n",
    "    imagem = cv2.imread(img_path)\n",
    "\n",
    "    # Verifique se a imagem foi carregada com sucesso\n",
    "    if imagem is None:\n",
    "        print(f\"Erro ao carregar a imagem: {img_path}\")\n",
    "        return None  # Retorne None para indicar que o processamento falhou\n",
    "\n",
    "    # Redimensionando a imagem\n",
    "    imagem_redimensionada = cv2.resize(imagem, (224, 224))\n",
    "\n",
    "    # Aumento de contraste\n",
    "    imagem_em_escala_de_cinza = cv2.cvtColor(imagem_redimensionada, cv2.COLOR_BGR2GRAY)\n",
    "    #imagem_em_escala_de_cinza = cv2.equalizeHist(imagem_em_escala_de_cinza)\n",
    "\n",
    "    # Expanda as dimensões para corresponder à forma esperada do modelo (1, 224, 224, 3)\n",
    "    imagem_processada = np.expand_dims(imagem_em_escala_de_cinza, axis=0)\n",
    "    imagem_processada = np.stack((imagem_processada,) * 3, axis=-1)  # Replica o canal em todos os três canais\n",
    "    imagem_processada = np.expand_dims(imagem_processada, axis=-1)\n",
    "    \n",
    "    # Normalizar a imagem\n",
    "    imagem_processada = imagem_processada / 255.0\n",
    "\n",
    "    return imagem_processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para fazer a classificação da imagem\n",
    "def classificar_imagem(imagem_path, nome_do_modelo):\n",
    "    model = carregar_ou_treinar_modelo(nome_do_modelo)  # Carrega ou treina o modelo\n",
    "    # Pré-processamento da imagem\n",
    "    imagem_processada = preprocess_image_for_prediction(imagem_path)\n",
    "\n",
    "    if imagem_processada is None:\n",
    "        return \"Falha no pré-processamento\", None\n",
    "\n",
    "    # Faça a previsão usando o modelo\n",
    "    previsao = model.predict(imagem_processada)\n",
    "\n",
    "    # Obtenha a classe prevista com a maior probabilidade\n",
    "    classe_prevista = np.argmax(previsao)\n",
    "\n",
    "    # Imprima as classes previstas e suas probabilidades\n",
    "    print(f\"\\n\\nResultado da classificação para a imagem: {imagem_path} usando o modelo: {nome_do_modelo}\")\n",
    "    print(\"\\nClassificação das 3 classes mais prováveis:\")\n",
    "    top_classes_indices = np.argsort(previsao[0])[::-1][:3]\n",
    "    top_classes_names = [labels[i] for i in top_classes_indices]\n",
    "    top_classes_probs = [previsao[0][i] for i in top_classes_indices]\n",
    "    for i, (classe, probabilidade) in enumerate(zip(top_classes_names, top_classes_probs), 1):\n",
    "        print(f\"{i}. Classe: {classe}, Probabilidade: {probabilidade:.4f}\")\n",
    "\n",
    "    # Imprima todas as classes e suas probabilidades\n",
    "    print(\"\\nProbabilidades para todas as classes:\")\n",
    "    for i, (classe, probabilidade) in enumerate(zip(labels, previsao[0]), 1):\n",
    "        print(f\"{i}. Classe: {classe}, Probabilidade: {probabilidade:.4f}\")\n",
    "\n",
    "    return labels[classe_prevista], previsao[0][classe_prevista]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5132 validated image filenames belonging to 8 classes.\n",
      "Found 1283 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "161/161 [==============================] - 312s 2s/step - loss: 1.9066 - accuracy: 0.4084 - val_loss: 0.8769 - val_accuracy: 0.6999\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 289s 2s/step - loss: 0.7269 - accuracy: 0.7399 - val_loss: 0.5768 - val_accuracy: 0.8059\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 289s 2s/step - loss: 0.3738 - accuracy: 0.8784 - val_loss: 0.5348 - val_accuracy: 0.8153\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 276s 2s/step - loss: 0.1845 - accuracy: 0.9415 - val_loss: 0.7273 - val_accuracy: 0.7958\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 272s 2s/step - loss: 0.1186 - accuracy: 0.9651 - val_loss: 0.6471 - val_accuracy: 0.8020\n",
      "41/41 [==============================] - 25s 580ms/step\n",
      "Found 5132 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1283 validated image filenames belonging to 8 classes.\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 293s 2s/step - loss: 1.8215 - accuracy: 0.4452 - val_loss: 1.2153 - val_accuracy: 0.5370\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 288s 2s/step - loss: 0.7266 - accuracy: 0.7504 - val_loss: 0.6766 - val_accuracy: 0.7553\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 285s 2s/step - loss: 0.3998 - accuracy: 0.8714 - val_loss: 0.7896 - val_accuracy: 0.7381\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 292s 2s/step - loss: 0.2076 - accuracy: 0.9396 - val_loss: 0.6431 - val_accuracy: 0.8051\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 285s 2s/step - loss: 0.1275 - accuracy: 0.9632 - val_loss: 0.8906 - val_accuracy: 0.7935\n",
      "41/41 [==============================] - 30s 706ms/step\n",
      "Found 5132 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1283 validated image filenames belonging to 8 classes.\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 534s 3s/step - loss: 1.5965 - accuracy: 0.4673 - val_loss: 0.8804 - val_accuracy: 0.6937\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 242s 2s/step - loss: 0.6780 - accuracy: 0.7611 - val_loss: 0.6315 - val_accuracy: 0.7942\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 236s 1s/step - loss: 0.3458 - accuracy: 0.8901 - val_loss: 0.5607 - val_accuracy: 0.8293\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 228s 1s/step - loss: 0.1748 - accuracy: 0.9439 - val_loss: 0.6617 - val_accuracy: 0.8215\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 246s 2s/step - loss: 0.1024 - accuracy: 0.9690 - val_loss: 1.0659 - val_accuracy: 0.7670\n",
      "41/41 [==============================] - 19s 449ms/step\n",
      "Found 5132 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1283 validated image filenames belonging to 8 classes.\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 232s 1s/step - loss: 1.5534 - accuracy: 0.4550 - val_loss: 0.9372 - val_accuracy: 0.6804\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 228s 1s/step - loss: 0.6678 - accuracy: 0.7687 - val_loss: 0.7177 - val_accuracy: 0.7623\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 221s 1s/step - loss: 0.3270 - accuracy: 0.8899 - val_loss: 0.6047 - val_accuracy: 0.8012\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 222s 1s/step - loss: 0.1556 - accuracy: 0.9509 - val_loss: 0.7821 - val_accuracy: 0.8028\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 255s 2s/step - loss: 0.0951 - accuracy: 0.9717 - val_loss: 0.8891 - val_accuracy: 0.7794\n",
      "41/41 [==============================] - 18s 442ms/step\n",
      "Found 5132 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1283 validated image filenames belonging to 8 classes.\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 234s 1s/step - loss: 1.7402 - accuracy: 0.3971 - val_loss: 1.1633 - val_accuracy: 0.5939\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 236s 1s/step - loss: 0.7832 - accuracy: 0.7210 - val_loss: 0.6570 - val_accuracy: 0.7724\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 227s 1s/step - loss: 0.3847 - accuracy: 0.8704 - val_loss: 0.6229 - val_accuracy: 0.7958\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 231s 1s/step - loss: 0.1789 - accuracy: 0.9478 - val_loss: 0.8029 - val_accuracy: 0.7981\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 229s 1s/step - loss: 0.1078 - accuracy: 0.9698 - val_loss: 0.9442 - val_accuracy: 0.8005\n",
      "41/41 [==============================] - 19s 450ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Especifique o nome do modelo desejado\n",
    "nome_do_modelo = 'image_classification.h5'\n",
    "\n",
    "# Carregue ou treine o modelo e obtenha as informações/estatísticas do fold\n",
    "model, fold_info = carregar_ou_treinar_modelo(nome_do_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 118ms/step\n",
      "\n",
      "\n",
      "Resultado da classificação para a imagem: e:\\zzzzzanime\\73.jpg usando o modelo: <keras.src.engine.sequential.Sequential object at 0x000001478EC811B0>\n",
      "\n",
      "Classificação das 3 classes mais prováveis:\n",
      "1. Classe: Pica_Pau, Probabilidade: 0.4996\n",
      "2. Classe: Bungo_Stray_Dogs, Probabilidade: 0.4409\n",
      "3. Classe: Kick_Buttowski, Probabilidade: 0.0316\n",
      "\n",
      "Probabilidades para todas as classes:\n",
      "1. Classe: Apenas_Um_Show, Probabilidade: 0.0016\n",
      "2. Classe: Bob_Esponja, Probabilidade: 0.0000\n",
      "3. Classe: Bungo_Stray_Dogs, Probabilidade: 0.4409\n",
      "4. Classe: Kick_Buttowski, Probabilidade: 0.0316\n",
      "5. Classe: Looney_Tunes, Probabilidade: 0.0261\n",
      "6. Classe: Madeline, Probabilidade: 0.0001\n",
      "7. Classe: Padrinhos_Magicos, Probabilidade: 0.0001\n",
      "8. Classe: Pica_Pau, Probabilidade: 0.4996\n",
      "\n",
      "O nome da classe prevista é: ('Pica_Pau', 0.49963942) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Insira o caminho da imagem que você deseja classificar\n",
    "imagem_path = os.path.join(script_dir, '73.jpg')\n",
    "\n",
    "# Em seguida, você pode realizar a classificação da imagem conforme anteriormente\n",
    "classe_prevista = classificar_imagem(imagem_path, model)\n",
    "print(f'\\nO nome da classe prevista é: {classe_prevista}','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Loss: [1.9065566062927246, 0.7269456386566162, 0.37381094694137573, 0.18453657627105713, 0.11859223991632462]\n",
      "Accuracy: [0.4084177613258362, 0.7398675084114075, 0.8784099817276001, 0.9415432810783386, 0.965120792388916]\n",
      "Validation Loss: [0.8768516182899475, 0.5768245458602905, 0.5348190665245056, 0.7272940278053284, 0.6471142768859863]\n",
      "Validation Accuracy: [0.6999220848083496, 0.8059236407279968, 0.8152766823768616, 0.7957910895347595, 0.8020265102386475]\n",
      "Matriz de Confusão:\n",
      "[[575   0  27  44  41  46   1  66]\n",
      " [  1 789   0   0   1   5   0   3]\n",
      " [ 26   0 667  21  21  24   1  40]\n",
      " [ 68   1  22 492  61  36   2 118]\n",
      " [ 42   1  26  42 505  53   1 130]\n",
      " [ 20   3  15  11  62 613   2  80]\n",
      " [  1   0   1   1   1   3 797   6]\n",
      " [ 19   1  18  19  75  47   1 620]]\n",
      "\n",
      "Precisão por Classe:\n",
      "Classe 'Apenas_Um_Show': Precisão = '0.7488'\n",
      "Classe 'Bob_Esponja': Precisão = '0.9937'\n",
      "Classe 'Bungo_Stray_Dogs': Precisão = '0.8836'\n",
      "Classe 'Kick_Buttowski': Precisão = '0.8525'\n",
      "Classe 'Looney_Tunes': Precisão = '0.6101'\n",
      "Classe 'Madeline': Precisão = '0.7714'\n",
      "Classe 'Padrinhos_Magicos': Precisão = '0.9934'\n",
      "Classe 'Pica_Pau': Precisão = '0.6453'\n",
      "Fold 2:\n",
      "Loss: [1.821482539176941, 0.7266061305999756, 0.3997662365436554, 0.20764145255088806, 0.12749868631362915]\n",
      "Accuracy: [0.44524550437927246, 0.7503896951675415, 0.8713951706886292, 0.9395946860313416, 0.9631722569465637]\n",
      "Validation Loss: [1.2153265476226807, 0.6765624284744263, 0.78963303565979, 0.6431186199188232, 0.8906179666519165]\n",
      "Validation Accuracy: [0.537022590637207, 0.7552611231803894, 0.7381138205528259, 0.805144190788269, 0.7934528589248657]\n",
      "Matriz de Confusão:\n",
      "[[137   0   7  11   0  11   0  10]\n",
      " [  0 156   0   0   0   2   0   2]\n",
      " [ 10   0 110   8   1   8   0   6]\n",
      " [ 17   0   5 122   3   5   0  15]\n",
      " [ 14   0   5  12  93  20   0  26]\n",
      " [ 10   0   1   4   2 127   0  14]\n",
      " [  1   0   0   0   0   1 161   0]\n",
      " [  6   0   4   9   4  11   0 112]]\n",
      "\n",
      "Precisão por Classe:\n",
      "Classe 'Apenas_Um_Show': Precisão = '0.7026'\n",
      "Classe 'Bob_Esponja': Precisão = '1.0000'\n",
      "Classe 'Bungo_Stray_Dogs': Precisão = '0.8333'\n",
      "Classe 'Kick_Buttowski': Precisão = '0.7349'\n",
      "Classe 'Looney_Tunes': Precisão = '0.9029'\n",
      "Classe 'Madeline': Precisão = '0.6865'\n",
      "Classe 'Padrinhos_Magicos': Precisão = '1.0000'\n",
      "Classe 'Pica_Pau': Precisão = '0.6054'\n",
      "Fold 3:\n",
      "Loss: [1.5964614152908325, 0.6779513955116272, 0.3457862436771393, 0.1747675985097885, 0.10239356011152267]\n",
      "Accuracy: [0.46726423501968384, 0.7611067891120911, 0.8901013135910034, 0.9438815116882324, 0.9690179228782654]\n",
      "Validation Loss: [0.8803620338439941, 0.6314852833747864, 0.5606985092163086, 0.661672830581665, 1.06594717502594]\n",
      "Validation Accuracy: [0.6936866641044617, 0.7942322492599487, 0.8293063044548035, 0.8215121030807495, 0.7669524550437927]\n",
      "Matriz de Confusão:\n",
      "[[ 92   0   0   4   4  17   1  16]\n",
      " [  1 166   0   0   1   2   0   1]\n",
      " [  2   0 133   4   7   8   0  20]\n",
      " [ 16   0   2  65  10  17   0  38]\n",
      " [  6   0   2   4  93   8   0  38]\n",
      " [  3   0   3   0  20 130   0  17]\n",
      " [  0   0   0   0   0   0 169   0]\n",
      " [  1   0   2   2   9  13   0 136]]\n",
      "\n",
      "Precisão por Classe:\n",
      "Classe 'Apenas_Um_Show': Precisão = '0.7603'\n",
      "Classe 'Bob_Esponja': Precisão = '1.0000'\n",
      "Classe 'Bungo_Stray_Dogs': Precisão = '0.9366'\n",
      "Classe 'Kick_Buttowski': Precisão = '0.8228'\n",
      "Classe 'Looney_Tunes': Precisão = '0.6458'\n",
      "Classe 'Madeline': Precisão = '0.6667'\n",
      "Classe 'Padrinhos_Magicos': Precisão = '0.9941'\n",
      "Classe 'Pica_Pau': Precisão = '0.5113'\n",
      "Fold 4:\n",
      "Loss: [1.5533956289291382, 0.6678147315979004, 0.32702523469924927, 0.15558455884456635, 0.0951114073395729]\n",
      "Accuracy: [0.4549883008003235, 0.7687061429023743, 0.8899064660072327, 0.9508963227272034, 0.9717459082603455]\n",
      "Validation Loss: [0.9371574521064758, 0.7177262306213379, 0.6046525239944458, 0.782084047794342, 0.8891431093215942]\n",
      "Validation Accuracy: [0.6804364919662476, 0.7622759342193604, 0.8012470602989197, 0.8028059005737305, 0.7794232368469238]\n",
      "Matriz de Confusão:\n",
      "[[100   0  12  13  17  10   0  15]\n",
      " [  0 166   0   0   0   1   0   0]\n",
      " [  3   0 142   2   6   1   1   7]\n",
      " [  7   1   5  87  12   7   1  31]\n",
      " [  3   1  12   4 113   8   0  23]\n",
      " [  2   1   4   4  17 126   2  12]\n",
      " [  0   0   1   0   0   0 151   1]\n",
      " [  2   0   7   3  15   8   1 115]]\n",
      "\n",
      "Precisão por Classe:\n",
      "Classe 'Apenas_Um_Show': Precisão = '0.8547'\n",
      "Classe 'Bob_Esponja': Precisão = '0.9822'\n",
      "Classe 'Bungo_Stray_Dogs': Precisão = '0.7760'\n",
      "Classe 'Kick_Buttowski': Precisão = '0.7699'\n",
      "Classe 'Looney_Tunes': Precisão = '0.6278'\n",
      "Classe 'Madeline': Precisão = '0.7826'\n",
      "Classe 'Padrinhos_Magicos': Precisão = '0.9679'\n",
      "Classe 'Pica_Pau': Precisão = '0.5637'\n",
      "Fold 5:\n",
      "Loss: [1.740229606628418, 0.7832155227661133, 0.3846636414527893, 0.17888504266738892, 0.10784606635570526]\n",
      "Accuracy: [0.39711612462997437, 0.7209664583206177, 0.8704208731651306, 0.9477786421775818, 0.9697973728179932]\n",
      "Validation Loss: [1.1632786989212036, 0.6570249199867249, 0.6228692531585693, 0.802901566028595, 0.9441920518875122]\n",
      "Validation Accuracy: [0.5939204692840576, 0.7724084258079529, 0.7957910895347595, 0.7981293797492981, 0.8004676699638367]\n",
      "Matriz de Confusão:\n",
      "[[ 94   0   3  10  14   3   0  15]\n",
      " [  0 144   0   0   0   0   0   0]\n",
      " [  2   0 153   4   3   2   0   2]\n",
      " [  9   0   7 114  19   4   0  20]\n",
      " [  6   0   3  16 109   7   1  19]\n",
      " [  2   1   4   2  11 122   0  20]\n",
      " [  0   0   0   0   0   1 165   3]\n",
      " [  3   1   3   4  25   7   0 126]]\n",
      "\n",
      "Precisão por Classe:\n",
      "Classe 'Apenas_Um_Show': Precisão = '0.8103'\n",
      "Classe 'Bob_Esponja': Precisão = '0.9863'\n",
      "Classe 'Bungo_Stray_Dogs': Precisão = '0.8844'\n",
      "Classe 'Kick_Buttowski': Precisão = '0.7600'\n",
      "Classe 'Looney_Tunes': Precisão = '0.6022'\n",
      "Classe 'Madeline': Precisão = '0.8356'\n",
      "Classe 'Padrinhos_Magicos': Precisão = '0.9940'\n",
      "Classe 'Pica_Pau': Precisão = '0.6146'\n",
      "\n",
      "Acurácia Média entre os 5 folds: 0.9678\n",
      "Acurácia de Validação Média entre os 5 folds: 0.7885\n",
      "\n",
      "Matriz de Confusão Geral (Somatório das Matrizes dos Folds):\n",
      "[[ 998    0   49   82   76   87    2  122]\n",
      " [   2 1421    0    0    2   10    0    6]\n",
      " [  43    0 1205   39   38   43    2   75]\n",
      " [ 117    2   41  880  105   69    3  222]\n",
      " [  71    2   48   78  913   96    2  236]\n",
      " [  37    5   27   21  112 1118    4  143]\n",
      " [   2    0    2    1    1    5 1443   10]\n",
      " [  31    2   34   37  128   86    2 1109]]\n",
      "\n",
      "Precisão Média por Classe:\n",
      "Classe 'Apenas_Um_Show': Precisão Média = '0.7753'\n",
      "Classe 'Bob_Esponja': Precisão Média = '0.9924'\n",
      "Classe 'Bungo_Stray_Dogs': Precisão Média = '0.8628'\n",
      "Classe 'Kick_Buttowski': Precisão Média = '0.7880'\n",
      "Classe 'Looney_Tunes': Precisão Média = '0.6778'\n",
      "Classe 'Madeline': Precisão Média = '0.7486'\n",
      "Classe 'Padrinhos_Magicos': Precisão Média = '0.9899'\n",
      "Classe 'Pica_Pau': Precisão Média = '0.5881'\n"
     ]
    }
   ],
   "source": [
    "# Exiba as informações/estatísticas do fold\n",
    "exibir_informacoes_fold(fold_info, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
